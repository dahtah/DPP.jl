<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>DPP.jl: a Julia package for sampling Determinantal Point Processes · DPP.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>DPP.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>DPP.jl: a Julia package for sampling Determinantal Point Processes</a><ul class="internal"><li><a class="toctext" href="#Quick-start-1">Quick start</a></li><li class="toplevel"><a class="toctext" href="#Inclusion-probabilities-1">Inclusion probabilities</a></li><li class="toplevel"><a class="toctext" href="#k-DPPs-1">k-DPPs</a></li><li><a class="toctext" href="#Functions-and-types-1">Functions and types</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>DPP.jl: a Julia package for sampling Determinantal Point Processes</a></li></ul><a class="edit-page" href="https://github.com//blob/master/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>DPP.jl: a Julia package for sampling Determinantal Point Processes</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="DPP.jl:-a-Julia-package-for-sampling-Determinantal-Point-Processes-1" href="#DPP.jl:-a-Julia-package-for-sampling-Determinantal-Point-Processes-1">DPP.jl: a Julia package for sampling Determinantal Point Processes</a></h1><p>DPP.jl provides some types and functions for sampling from DPPs (and related models). </p><h2><a class="nav-anchor" id="Quick-start-1" href="#Quick-start-1">Quick start</a></h2><p>To define a DPP, first define an L-ensemble. The L-ensemble can either be defined as:</p><ul><li>full-rank, in which case it&#39;s represented as a <span>$n \times n$</span> matrix <span>$\mathbf{L}$</span></li><li>low-rank, in which case it&#39;s represented as <span>$\mathbf{L} = \mathbf{M}\mathbf{M}^t$</span> where <span>$\mathbf{M}$</span> is <span>$n \times m$</span>, <span>$m \leq n$</span>. Low-rank ensembles are always faster to sample from. </li><li>&quot;projection&quot;, which is just like low-rank, expect you&#39;re restricted to sampling exactly <span>$m$</span> points (i.e., the rank of the matrix)</li></ul><p>An example for full-rank L-ensembles:</p><pre><code class="language-julia">using DPP
X = randn(2,1000) #1,000 points in dim 2
L = DPP.gaussker(X,.5) |&gt; FullRankEnsemble
rescale!(L,40)
ind = sample(L) |&gt; collect #sample returns a BitSet, we collect all indices

# On this plot the original points are in grey, the sampled ones in red
using Plots
Plots.scatter(X[1,:],X[2,:],color=:gray,alpha=.5)
Plots.scatter!(X[1,ind],X[2,ind],color=:red,alpha=1)</code></pre><pre><code class="language-none">Qt: Session management error: Could not open network socket</code></pre><p><img src="test.svg" alt/></p><p>For low-rank ensembles, we can use an RFF approximation:</p><pre><code class="language-julia">Lr = rff(X,150,.5) |&gt; LowRankEnsemble
rescale!(Lr,40)
ind = sample(Lr) |&gt; collect
Plots.scatter(X[1,:],X[2,:],color=:gray,alpha=.5) # hide
Plots.scatter!(X[1,ind],X[2,ind],color=:red,alpha=1) # hide
savefig(&quot;test2.svg&quot;) # hide</code></pre><pre><code class="language-none">┌ Warning: Numerical rank is lower than number of matrix columns
└ @ DPP ~/Repos/DPP.jl/src/lensemble.jl:58
Qt: Session management error: Could not open network socket</code></pre><p><img src="test2.svg" alt/></p><p>Example using polynomial features and a projection ensemble: </p><pre><code class="language-julia">Lp = polyfeatures(X,10) |&gt; ProjectionEnsemble
ind = sample(Lp) |&gt; collect
Plots.scatter(X[1,:],X[2,:],color=:gray,alpha=.5) # hide
Plots.scatter!(X[1,ind],X[2,ind],color=:red,alpha=1) # hide
savefig(&quot;test3.svg&quot;); # hide</code></pre><pre><code class="language-none">Qt: Session management error: Could not open network socket</code></pre><p><img src="test3.svg" alt/></p><h1><a class="nav-anchor" id="Inclusion-probabilities-1" href="#Inclusion-probabilities-1">Inclusion probabilities</a></h1><p>An attractive aspect of DPPs is that inclusion probabilities are easy to compute. An inclusion probability is the probability that a certain item (or items) is included in the random set produced by a DPP. </p><pre><code class="language-julia">using StatsBase
#sample 1,000 times and compute empirical inclusion frequencies
reps = [StatsBase.counts(collect(sample(Lr)),1:Lr.n) for _ in 1:1000];
#compare to theoretical values
scatter(inclusion_prob(Lr),mean(reps))
savefig(&quot;example_incl.svg&quot;); # hide</code></pre><pre><code class="language-none">WARNING: using StatsBase.sample in module ex-1 conflicts with an existing identifier.
Qt: Session management error: Could not open network socket</code></pre><p><img src="example_incl.svg" alt/></p><p>So far these are just first-order inclusion probabilities. More generally, you can obtain higher-order probabilities (ie prob that items i,j,k,... are in the set <em>jointly</em>) from the marginal kernel of the DPP, given by &quot;marginal_kernel&quot;</p><p>In the next example we compute the empirical inclusion probability of a set of items:</p><pre><code class="language-julia">using LinearAlgebra
X = randn(2,10)
L = DPP.gaussker(X,.5) |&gt; FullRankEnsemble
rescale!(L,4)
set = [3,5]

incl = [ length(intersect(set,sample(L)))==length(set) for _ in 1:10000];
#empirical inclusion prob.
emp = mean(incl)</code></pre><pre><code class="language-none">0.1352</code></pre><p>The theoretical value is given by </p><pre><code class="language-julia">th = det(marginal_kernel(L)[set,set])</code></pre><pre><code class="language-none">0.13671749599737715</code></pre><h1><a class="nav-anchor" id="k-DPPs-1" href="#k-DPPs-1">k-DPPs</a></h1><p>Generally, a DPP will generate a subset of random size (except for projection DPPs). If you&#39;d like to sample a subset of fixed size, use a k-DPP. Specifying a size argument in the &quot;sample&quot; function will do the trick: </p><pre><code class="language-julia">sample(Lr,20) |&gt; length</code></pre><pre><code class="language-none">20</code></pre><p>Be careful, k-DPPs do not have a marginal kernel. Although the inclusion probabilities are nominally intractable, there exist good approximations that can be computed quickly. Use <em>inclusion_prob</em> and specify <em>k</em> to get approximate first-order inclusion probabilities. </p><h2><a class="nav-anchor" id="Functions-and-types-1" href="#Functions-and-types-1">Functions and types</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DPP.gaussker-Tuple{Array{T,2} where T,Any}" href="#DPP.gaussker-Tuple{Array{T,2} where T,Any}"><code>DPP.gaussker</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">gaussker(X,σ)</code></pre><p>Compute the Gaussian kernel matrix for X and parameter σ, ie. a matrix with entry i,j equal to <span>$\exp(-\frac{(x_i-x_j)^2}{2σ^2})$</span></p><p>See also: rff, kernelmatrix </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DPP.inclusion_prob-Tuple{DPP.AbstractLEnsemble,Any}" href="#DPP.inclusion_prob-Tuple{DPP.AbstractLEnsemble,Any}"><code>DPP.inclusion_prob</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">inclusion_prob(L::AbstractLEnsemble,k)</code></pre><p>First-order inclusion probabilities in a k-DPP with L-ensemble L. Uses a (typically very accurate) saddlepoint approximation from Barthelmé, Amblard, Tremblay (2019). </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DPP.inclusion_prob-Tuple{DPP.AbstractLEnsemble}" href="#DPP.inclusion_prob-Tuple{DPP.AbstractLEnsemble}"><code>DPP.inclusion_prob</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>inclusion_prob(L::AbstractLEnsemble)</p><p>Compute first-order inclusion probabilities, i.e. the probability that each item in 1..n is included in the DPP.</p><p>See also: marginal_kernel</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DPP.marginal_kernel-Tuple{DPP.AbstractLEnsemble}" href="#DPP.marginal_kernel-Tuple{DPP.AbstractLEnsemble}"><code>DPP.marginal_kernel</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia"> marginal_kernel(L::AbstractLEnsemble)</code></pre><p>Compute and return the marginal kernel of a DPP, K. The marginal kernel of a DPP is a (n x n) matrix which can be used to find the inclusion probabilities. For any fixed set of indices ind, the probability that ind is included in a sample from the DPP equals det(K[ind,ind]). </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DPP.polyfeatures-Union{Tuple{T}, Tuple{Array{T,2},Int64}} where T&lt;:Real" href="#DPP.polyfeatures-Union{Tuple{T}, Tuple{Array{T,2},Int64}} where T&lt;:Real"><code>DPP.polyfeatures</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">polyfeatures(X,order)</code></pre><p>Compute monomial features up to a certain degree. For instance, if X is a 2 x n matrix and the degree argument equals 2, it will return a matrix with columns 1,X[1,:],X[2,:],X[1,:].^2,X[2,:].^2,X[1,:]*X[2,:] Note that the number of monomials of degree r in dimension d equals <span>${ d+r \choose r}$</span></p><p>X is assumed to be of dimension <span>$d \times n$</span> where d is the dimension and n is the number of points.</p><p><strong>Examples</strong></p><pre><code class="language-none">X = randn(2,10) #10 points in dim 2
polyfeatures(X,2) #Output has three columns</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DPP.rescale!" href="#DPP.rescale!"><code>DPP.rescale!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>rescale!(L,k)</p><p><span>$\DeclareMathOperator{\Tr}{Tr}$</span></p><p>Rescale the L-ensemble such that the expected number of samples equals k. The expected number of samples of a DPP equals <span>$\Tr \mathbf{L}\left( \mathbf{L} + \mathbf{I} \right)$</span>. The function rescales <span>$\mathbf{L}$</span> to <span>$\alpha \mathbf{L}$</span> such that <span>$\Tr \alpha \mathbf{L}\left( \alpha \mathbf{L} + \mathbf{I} \right) = k$</span></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DPP.rff-Tuple{Array{T,2} where T,Any,Any}" href="#DPP.rff-Tuple{Array{T,2} where T,Any,Any}"><code>DPP.rff</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">rff(X,m,σ)</code></pre><p>Compute Random Fourier Features for the Gaussian kernel matrix with input points X and parameter σ. Returns a random matrix M such that, in expectation <span>$\mathbf{MM}^t = \mathbf{K}$</span>, the Gaussian kernel matrix.  M has 2*m columns. The higher m, the better the approximation. </p><p><strong>Examples</strong></p><pre><code class="language-none">X = randn(2,10) #10 points in dim 2
rff(X,4,1.0)</code></pre><p>See also: gaussker, kernelmatrix </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DPP.sample-Tuple{DPP.AbstractLEnsemble,Any}" href="#DPP.sample-Tuple{DPP.AbstractLEnsemble,Any}"><code>DPP.sample</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">sample(L::AbstractLEnsemble,k)</code></pre><p>Sample a k-DPP, i.e. a DPP with fixed size. k needs to be strictly smaller than the rank of L (if it equals the rank of L, use a ProjectionEnsemble). </p><p>The algorithm uses a saddle-point approximation adapted from Barthelmé, Amblard, Tremblay (2019). </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DPP.sample-Tuple{ProjectionEnsemble}" href="#DPP.sample-Tuple{ProjectionEnsemble}"><code>DPP.sample</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia"> sample(L::AbstractEnsemble)</code></pre><p>Sample from a DPP with L-ensemble L. The return type is a BitSet (indicating which indices are sampled), use collect to get a vector of indices instead.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DPP.FullRankEnsemble" href="#DPP.FullRankEnsemble"><code>DPP.FullRankEnsemble</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>FullRankEnsemble{T}</p><p>This type represents an L-ensemble where the matrix L is full rank. This is the most general representation of an L-ensemble, but also the least efficient, both in terms of memory and computation.</p><p>At construction, an eigenvalue decomposition of L will be performed, at O(n^3) cost.</p><p>The type parameter corresponds to the type of the entries in the matrix given as input (most likely, double precision floats). </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DPP.FullRankEnsemble-Union{Tuple{Array{T,2}}, Tuple{T}} where T" href="#DPP.FullRankEnsemble-Union{Tuple{Array{T,2}}, Tuple{T}} where T"><code>DPP.FullRankEnsemble</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>FullRankEnsemble(V::Matrix{T})</p><p>Construct a full-rank ensemble from a matrix. Here the matrix must be square. </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DPP.FullRankEnsemble-Union{Tuple{T}, Tuple{Array{T,2},Kernel}} where T" href="#DPP.FullRankEnsemble-Union{Tuple{T}, Tuple{Array{T,2},Kernel}} where T"><code>DPP.FullRankEnsemble</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>FullRankEnsemble(X::Matrix{T},k :: Kernel)</p><p>Construct a full-rank ensemble from a set of points and a kernel function.</p><p>X (the set of points) is assumed to have dimension d x n, where d is the dimension and n is the number of points. k is a kernel (see doc for package MLKernels)</p><p>Example: points in 2d along the circle, and an exponential kernel</p><pre><code class="language-none">t = LinRange(-pi,pi,10)&#39;
X = vcat(cos.(t),sin.(t))
using MLKernels
L=FullRankEnsemble(X,ExponentialKernel(.1))</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DPP.LowRankEnsemble" href="#DPP.LowRankEnsemble"><code>DPP.LowRankEnsemble</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>This type represents an L-ensemble where the matrix L is low rank. This enables faster computation. </p><p>The type parameter corresponds to the type of the entries in the matrix given as input (most likely, double precision floats)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DPP.LowRankEnsemble-Union{Tuple{Array{T,2}}, Tuple{T}} where T" href="#DPP.LowRankEnsemble-Union{Tuple{Array{T,2}}, Tuple{T}} where T"><code>DPP.LowRankEnsemble</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>LowRankEnsemble(V::Matrix{T})</p><p>Construct a low-rank ensemble from a matrix of features. Here we assume  <span>$\mathbf{L} = \mathbf{V}\mathbf{V}^t$</span>, so that V must be n \times r, where n is the number of items and r is the rank of the L-ensemble.</p><p>You will not be able to sample a number of items greater than the rank. At construction, an eigenvalue decomposition of V&#39;*V will be perfomed, with cost nr^2. </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DPP.ProjectionEnsemble-Union{Tuple{Array{T,2}}, Tuple{T}, Tuple{Array{T,2},Any}} where T" href="#DPP.ProjectionEnsemble-Union{Tuple{Array{T,2}}, Tuple{T}, Tuple{Array{T,2},Any}} where T"><code>DPP.ProjectionEnsemble</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>ProjectionEnsemble(V::Matrix{T},orth=true)</p><p>Construct a projection ensemble from a matrix of features. Here we assume  <span>$\mathbf{L} = \mathbf{V}\mathbf{V}^t$</span>, so that V must be n \times r, where n is the number of items and r is the rank. V needs not be orthogonal. If orth is set to true (default), then a QR decomposition is performed. If V is orthogonal already, then this computation may be skipped, and you can set orth to false. </p></div></div></section><footer><hr/></footer></article></body></html>
